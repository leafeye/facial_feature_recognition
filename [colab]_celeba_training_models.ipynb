{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "celeba_training_models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "NOdSlhcJ2CDU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NxUsMOLm4umW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.metrics import roc_curve"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "snAQWFwzur-P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOpGuXdkWiK8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IQ2HCWFT2KE0",
        "colab_type": "code",
        "outputId": "b9383599-80d3-4ee1-9981-26b8ab078c18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hL0bnn1l2OmW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Colab/thesis/celeba/celeba_merged_embedding_attributes.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "87Uc9tC42S-d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "emb = np.load('/content/drive/My Drive/Colab/thesis/celeba/celeb_emb_npy.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cw2IMsug2mt2",
        "colab_type": "code",
        "outputId": "e443cde9-52db-4eef-8f1b-00dafa055709",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "emb.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(201498, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "metadata": {
        "id": "0TODpCkn2pmN",
        "colab_type": "code",
        "outputId": "a92047e6-0b85-495f-be81-7867034bedfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(201498, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "zzwXr-5d2r-y",
        "colab_type": "code",
        "outputId": "c8630c8d-ae48-4db3-c219-995867e2b9a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        }
      },
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>encodings</th>\n",
              "      <th>file</th>\n",
              "      <th>Male</th>\n",
              "      <th>Black_Hair</th>\n",
              "      <th>Blond_Hair</th>\n",
              "      <th>Brown_Hair</th>\n",
              "      <th>Bald</th>\n",
              "      <th>Eyeglasses</th>\n",
              "      <th>Mustache</th>\n",
              "      <th>No_Beard</th>\n",
              "      <th>Goatee</th>\n",
              "      <th>5_o_Clock_Shadow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-0.10657232  0.12290111  0.06805265 -0.041072...</td>\n",
              "      <td>000001.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-0.11027038  0.02495586  0.05625371 -0.070694...</td>\n",
              "      <td>000002.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-0.12229778  0.20610951  0.05414608 -0.035753...</td>\n",
              "      <td>000003.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-1.84543923e-01  1.76940337e-01  1.39256537e-...</td>\n",
              "      <td>000004.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-0.08415149  0.0511583   0.01261529 -0.051950...</td>\n",
              "      <td>000005.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[-0.01535916 -0.00451871  0.01638835  0.017832...</td>\n",
              "      <td>000006.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[-1.45129263e-01  6.18378632e-02  6.61352053e-...</td>\n",
              "      <td>000007.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[ 0.02644151  0.15732542 -0.0238539   0.008128...</td>\n",
              "      <td>000008.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[-0.14153117  0.04991306  0.09734342 -0.129968...</td>\n",
              "      <td>000009.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[-0.09212744  0.14240824 -0.02830539 -0.158743...</td>\n",
              "      <td>000010.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           encodings        file  Male  \\\n",
              "0  [-0.10657232  0.12290111  0.06805265 -0.041072...  000001.jpg     0   \n",
              "1  [-0.11027038  0.02495586  0.05625371 -0.070694...  000002.jpg     0   \n",
              "2  [-0.12229778  0.20610951  0.05414608 -0.035753...  000003.jpg     1   \n",
              "3  [-1.84543923e-01  1.76940337e-01  1.39256537e-...  000004.jpg     0   \n",
              "4  [-0.08415149  0.0511583   0.01261529 -0.051950...  000005.jpg     0   \n",
              "5  [-0.01535916 -0.00451871  0.01638835  0.017832...  000006.jpg     0   \n",
              "6  [-1.45129263e-01  6.18378632e-02  6.61352053e-...  000007.jpg     1   \n",
              "7  [ 0.02644151  0.15732542 -0.0238539   0.008128...  000008.jpg     1   \n",
              "8  [-0.14153117  0.04991306  0.09734342 -0.129968...  000009.jpg     0   \n",
              "9  [-0.09212744  0.14240824 -0.02830539 -0.158743...  000010.jpg     0   \n",
              "\n",
              "   Black_Hair  Blond_Hair  Brown_Hair  Bald  Eyeglasses  Mustache  No_Beard  \\\n",
              "0           0           0           1     0           0         0         1   \n",
              "1           0           0           1     0           0         0         1   \n",
              "2           0           0           0     0           0         0         1   \n",
              "3           0           0           0     0           0         0         1   \n",
              "4           0           0           0     0           0         0         1   \n",
              "5           0           0           1     0           0         0         1   \n",
              "6           1           0           0     0           0         0         1   \n",
              "7           1           0           0     0           0         0         1   \n",
              "8           0           0           0     0           0         0         1   \n",
              "9           0           0           0     0           0         0         1   \n",
              "\n",
              "   Goatee  5_o_Clock_Shadow  \n",
              "0       0                 0  \n",
              "1       0                 0  \n",
              "2       0                 0  \n",
              "3       0                 0  \n",
              "4       0                 0  \n",
              "5       0                 0  \n",
              "6       0                 1  \n",
              "7       0                 1  \n",
              "8       0                 0  \n",
              "9       0                 0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "IySliSZL4N1-",
        "colab_type": "code",
        "outputId": "5f2dd0c8-d571-44e6-f17d-c2ef45165f06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "df.Male.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    117723\n",
              "1     83775\n",
              "Name: Male, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "O5MjrtVu9IVE",
        "colab_type": "code",
        "outputId": "e2c56942-b51c-4b51-93b6-3d7161f21891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "df.Male[:20000].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    11589\n",
              "1     8411\n",
              "Name: Male, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "al5MgIRU3Gjl",
        "colab_type": "code",
        "outputId": "41ff66ec-cdab-4233-ba15-1902e31124df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "male = df.Male.values\n",
        "male"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "metadata": {
        "id": "AnKVQYXs8X0k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#test with small subset\n",
        "male_sub = male[:20000]\n",
        "emb_sub = emb[:20000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iRFRnidX9V06",
        "colab_type": "code",
        "outputId": "6e971c14-68f1-40d2-c312-077287edfcfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "emb_sub.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "iCRr9iG15TdH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#subset\n",
        "X_train,X_test,y_train,y_test = train_test_split(emb_sub, male_sub,test_size=0.25,random_state=91, stratify=male_sub)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mDGTiXtH5iaa",
        "colab_type": "code",
        "outputId": "51196351-c431-4108-c27e-c2abd19a567c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "print('train')\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print('test')\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "(15000, 128)\n",
            "(15000,)\n",
            "test\n",
            "(5000, 128)\n",
            "(5000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zN6lyv9E6lGU",
        "colab_type": "code",
        "outputId": "1932a123-3c88-403e-a04d-3f1411d7696b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "model = SGDClassifier(loss='log', random_state=91, max_iter=5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"{:.3}\".format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.984\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99      2897\n",
            "           1       0.99      0.98      0.98      2103\n",
            "\n",
            "   micro avg       0.98      0.98      0.98      5000\n",
            "   macro avg       0.98      0.98      0.98      5000\n",
            "weighted avg       0.98      0.98      0.98      5000\n",
            "\n",
            "[[2870   27]\n",
            " [  51 2052]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "DtG6iyuN_agv",
        "colab_type": "code",
        "outputId": "66892817-105d-4423-ab9f-b582adcefbd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "model = SGDClassifier(loss='hinge', random_state=91, max_iter=5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"{:.3}\".format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.984\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99      2897\n",
            "           1       0.99      0.97      0.98      2103\n",
            "\n",
            "   micro avg       0.98      0.98      0.98      5000\n",
            "   macro avg       0.98      0.98      0.98      5000\n",
            "weighted avg       0.98      0.98      0.98      5000\n",
            "\n",
            "[[2874   23]\n",
            " [  58 2045]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q-K-T73_BO4H",
        "colab_type": "code",
        "outputId": "807f1281-d7d0-4583-ba98-f55b32c20ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "#full dataset\n",
        "X_train,X_test,y_train,y_test = train_test_split(emb, male,test_size=0.25,random_state=91, stratify=male)\n",
        "\n",
        "print('train')\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print('test')\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "(151123, 128)\n",
            "(151123,)\n",
            "test\n",
            "(50375, 128)\n",
            "(50375,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K9PqrRvKBd2w",
        "colab_type": "code",
        "outputId": "fd27f17b-4ce3-4d1e-cb77-0f6bddd16627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "model = SGDClassifier(loss='log', random_state=91, max_iter=40)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"{:.3}\".format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.984\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99     29431\n",
            "           1       0.98      0.98      0.98     20944\n",
            "\n",
            "   micro avg       0.98      0.98      0.98     50375\n",
            "   macro avg       0.98      0.98      0.98     50375\n",
            "weighted avg       0.98      0.98      0.98     50375\n",
            "\n",
            "[[29089   342]\n",
            " [  476 20468]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4FbZ-ijVN-MG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# save the model to disk\n",
        "filename = 'gender_model.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EKRTRkkWB-fi",
        "colab_type": "code",
        "outputId": "96473484-9a4f-4f4f-8e73-ac8fe1f613f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "model = SGDClassifier(loss='hinge', random_state=91, max_iter=5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"{:.3}\".format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.984\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99     29431\n",
            "           1       0.99      0.98      0.98     20944\n",
            "\n",
            "   micro avg       0.98      0.98      0.98     50375\n",
            "   macro avg       0.98      0.98      0.98     50375\n",
            "weighted avg       0.98      0.98      0.98     50375\n",
            "\n",
            "[[29131   300]\n",
            " [  515 20429]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4frGfzwUDw-j",
        "colab_type": "code",
        "outputId": "06a28e01-1faa-4049-f8c0-5068d01b32f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "model = SGDClassifier(loss='perceptron', random_state=91, max_iter=6)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"{:.3}\".format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.984\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99     29431\n",
            "           1       0.98      0.98      0.98     20944\n",
            "\n",
            "   micro avg       0.98      0.98      0.98     50375\n",
            "   macro avg       0.98      0.98      0.98     50375\n",
            "weighted avg       0.98      0.98      0.98     50375\n",
            "\n",
            "[[29097   334]\n",
            " [  469 20475]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5iwIISJkYYlr",
        "colab_type": "code",
        "outputId": "45ee8646-654c-46a3-a5fe-4274d3e7e827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(solver='adam', hidden_layer_sizes=(128, 128),max_iter = 40, verbose=True, tol=1e-4, activation='tanh')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "score = clf.predict_proba(X_test)\n",
        "\n",
        "print(\"{:.3}\".format(accuracy_score(y_test, y_pred)))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.07176806\n",
            "Iteration 2, loss = 0.05453825\n",
            "Iteration 3, loss = 0.05372543\n",
            "Iteration 4, loss = 0.05402774\n",
            "Iteration 5, loss = 0.05342143\n",
            "Iteration 6, loss = 0.05276486\n",
            "Iteration 7, loss = 0.05208719\n",
            "Iteration 8, loss = 0.05176349\n",
            "Iteration 9, loss = 0.05137487\n",
            "Iteration 10, loss = 0.05106549\n",
            "Iteration 11, loss = 0.05055762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.984\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99     29431\n",
            "           1       0.98      0.98      0.98     20944\n",
            "\n",
            "   micro avg       0.98      0.98      0.98     50375\n",
            "   macro avg       0.98      0.98      0.98     50375\n",
            "weighted avg       0.98      0.98      0.98     50375\n",
            "\n",
            "[[29118   313]\n",
            " [  477 20467]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K7Fk1wXs78l8",
        "colab_type": "code",
        "outputId": "fa5f06ce-e693-412a-85e9-b67e80b35789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#optimizers.RMSprop(lr=1e-4)\n",
        "\n",
        "hidden = 100\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(hidden, use_bias='true', activation='relu', input_shape=(128,)))\n",
        "network.add(layers.Dense(1, use_bias='true', activation='sigmoid'))\n",
        "\n",
        "keras.initializers.RandomNormal(mean=0.0, stddev=0.05)\n",
        "\n",
        "#keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
        "\n",
        "network.compile(optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "network.fit(X_train, y_train, epochs=30, batch_size=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "151123/151123 [==============================] - 13s 88us/step - loss: 0.0689 - acc: 0.9803\n",
            "Epoch 2/30\n",
            "151123/151123 [==============================] - 12s 83us/step - loss: 0.0538 - acc: 0.9849\n",
            "Epoch 3/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0526 - acc: 0.9852\n",
            "Epoch 4/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0514 - acc: 0.9852\n",
            "Epoch 5/30\n",
            "151123/151123 [==============================] - 12s 83us/step - loss: 0.0502 - acc: 0.9856\n",
            "Epoch 6/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0490 - acc: 0.9859\n",
            "Epoch 7/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0482 - acc: 0.9860\n",
            "Epoch 8/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0473 - acc: 0.9861\n",
            "Epoch 9/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0464 - acc: 0.9866\n",
            "Epoch 10/30\n",
            "151123/151123 [==============================] - 12s 83us/step - loss: 0.0455 - acc: 0.9866\n",
            "Epoch 11/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0448 - acc: 0.9867\n",
            "Epoch 12/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0443 - acc: 0.9869\n",
            "Epoch 13/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0434 - acc: 0.9871\n",
            "Epoch 14/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0427 - acc: 0.9873\n",
            "Epoch 15/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0422 - acc: 0.9874\n",
            "Epoch 16/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0417 - acc: 0.9875\n",
            "Epoch 17/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0410 - acc: 0.9877\n",
            "Epoch 18/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0404 - acc: 0.9878\n",
            "Epoch 19/30\n",
            "151123/151123 [==============================] - 12s 83us/step - loss: 0.0400 - acc: 0.9879\n",
            "Epoch 20/30\n",
            "151123/151123 [==============================] - 13s 83us/step - loss: 0.0395 - acc: 0.9879\n",
            "Epoch 21/30\n",
            "151123/151123 [==============================] - 13s 83us/step - loss: 0.0390 - acc: 0.9882\n",
            "Epoch 22/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0385 - acc: 0.9883\n",
            "Epoch 23/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0381 - acc: 0.9885\n",
            "Epoch 24/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0376 - acc: 0.9885\n",
            "Epoch 25/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0371 - acc: 0.9887\n",
            "Epoch 26/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0366 - acc: 0.9887\n",
            "Epoch 27/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0361 - acc: 0.9887\n",
            "Epoch 28/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0358 - acc: 0.9889\n",
            "Epoch 29/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0353 - acc: 0.9889\n",
            "Epoch 30/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0348 - acc: 0.9892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2200abbf60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "metadata": {
        "id": "uxiXjCgA89Ti",
        "colab_type": "code",
        "outputId": "fb06ce18-1ca8-46b4-8a0a-875b2423f1f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred = network.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "#score = network.predict_proba(X_test)\n",
        "\n",
        "print(\"{:.3}\".format(accuracy_score(y_test, y_pred)))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.986\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99     29431\n",
            "           1       0.99      0.98      0.98     20944\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     50375\n",
            "   macro avg       0.99      0.99      0.99     50375\n",
            "weighted avg       0.99      0.99      0.99     50375\n",
            "\n",
            "[[29170   261]\n",
            " [  434 20510]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M4p02k5F9uCZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename = 'gender_keras_model.sav'\n",
        "pickle.dump(network, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DpjpJFL0GXtZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# glasses"
      ]
    },
    {
      "metadata": {
        "id": "7hMW772mHL5R",
        "colab_type": "code",
        "outputId": "53bc27f1-f720-47ad-867b-e73ac6aa76a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "df.Eyeglasses.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    188449\n",
              "1     13049\n",
              "Name: Eyeglasses, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "sy9vxjgBGXHl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "glas = df.Eyeglasses.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZFAbSrUnGpyR",
        "colab_type": "code",
        "outputId": "977ade82-2bd7-4798-c142-ff01761d6ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "glas"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "metadata": {
        "id": "ECjhdB6lGwRM",
        "colab_type": "code",
        "outputId": "1466e28a-703e-432e-8555-0eaac34ecf2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(emb, glas,test_size=0.25,random_state=91, stratify=glas)\n",
        "\n",
        "print('train')\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print('test')\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "(151123, 128)\n",
            "(151123,)\n",
            "test\n",
            "(50375, 128)\n",
            "(50375,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1HH8XFtQG5rL",
        "colab_type": "code",
        "outputId": "20b195af-4229-444b-d52e-6cbea822b213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "model = SGDClassifier(loss='log', random_state=91, max_iter=5)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"{:.3}\".format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.951\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97     47113\n",
            "           1       0.93      0.27      0.42      3262\n",
            "\n",
            "   micro avg       0.95      0.95      0.95     50375\n",
            "   macro avg       0.94      0.63      0.70     50375\n",
            "weighted avg       0.95      0.95      0.94     50375\n",
            "\n",
            "[[47051    62]\n",
            " [ 2382   880]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KB5gskztHfiN",
        "colab_type": "code",
        "outputId": "41cb3887-caae-4415-9051-002e9c8f4e70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "model = SGDClassifier(loss='hinge', random_state=91, max_iter=40)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"{:.3}\".format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.955\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.98     47113\n",
            "           1       0.96      0.31      0.47      3262\n",
            "\n",
            "   micro avg       0.95      0.95      0.95     50375\n",
            "   macro avg       0.96      0.66      0.72     50375\n",
            "weighted avg       0.96      0.95      0.94     50375\n",
            "\n",
            "[[47075    38]\n",
            " [ 2241  1021]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AD1o-_e1OPMd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename = 'glasses_model.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MtioTLU2ahGD",
        "colab_type": "code",
        "outputId": "b2fd0d5c-8bf2-4132-a17f-fb78603bbe63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(solver='adam', hidden_layer_sizes=(128, 128),max_iter = 25, verbose=True, tol=1e-4, activation='relu')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "score = clf.predict_proba(X_test)\n",
        "\n",
        "print(\"{:.3}\".format(accuracy_score(y_test, y_pred)))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.15866756\n",
            "Iteration 2, loss = 0.09410872\n",
            "Iteration 3, loss = 0.06852118\n",
            "Iteration 4, loss = 0.05879127\n",
            "Iteration 5, loss = 0.05197428\n",
            "Iteration 6, loss = 0.04708383\n",
            "Iteration 7, loss = 0.04490795\n",
            "Iteration 8, loss = 0.04204692\n",
            "Iteration 9, loss = 0.03975551\n",
            "Iteration 10, loss = 0.03826528\n",
            "Iteration 11, loss = 0.03690978\n",
            "Iteration 12, loss = 0.03588126\n",
            "Iteration 13, loss = 0.03438935\n",
            "Iteration 14, loss = 0.03446756\n",
            "Iteration 15, loss = 0.03291528\n",
            "Iteration 16, loss = 0.03197527\n",
            "Iteration 17, loss = 0.03113957\n",
            "Iteration 18, loss = 0.03055257\n",
            "Iteration 19, loss = 0.02936187\n",
            "Iteration 20, loss = 0.03018748\n",
            "Iteration 21, loss = 0.02829025\n",
            "Iteration 22, loss = 0.02807101\n",
            "Iteration 23, loss = 0.02762381\n",
            "Iteration 24, loss = 0.02690086\n",
            "Iteration 25, loss = 0.02684036\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (25) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.986\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99     47113\n",
            "           1       0.91      0.87      0.89      3262\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     50375\n",
            "   macro avg       0.95      0.93      0.94     50375\n",
            "weighted avg       0.99      0.99      0.99     50375\n",
            "\n",
            "[[46840   273]\n",
            " [  408  2854]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BRycvflIcRI6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename = 'glasses_mlp_model.sav'\n",
        "pickle.dump(clf, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KkZ7nssAyK4J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_labels = to_categorical(y_train)\n",
        "test_labels = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V7aOzwnswAZ7",
        "colab_type": "code",
        "outputId": "48970edb-188c-4550-dce1-728544a2eaed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#optimizers.RMSprop(lr=1e-4)\n",
        "\n",
        "hidden = 128\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(hidden, use_bias='true', activation='relu', input_shape=(128,)))\n",
        "network.add(layers.Dense(1, use_bias='true', activation='sigmoid'))\n",
        "\n",
        "keras.initializers.RandomNormal(mean=0.0, stddev=0.05)\n",
        "\n",
        "#keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
        "\n",
        "network.compile(optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "network.fit(X_train, y_train, epochs=30, batch_size=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.1579 - acc: 0.9502\n",
            "Epoch 2/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.1296 - acc: 0.9600\n",
            "Epoch 3/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.1148 - acc: 0.9632\n",
            "Epoch 4/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0999 - acc: 0.9663\n",
            "Epoch 5/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0866 - acc: 0.9697\n",
            "Epoch 6/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0767 - acc: 0.9736\n",
            "Epoch 7/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0691 - acc: 0.9759\n",
            "Epoch 8/30\n",
            "151123/151123 [==============================] - 12s 81us/step - loss: 0.0635 - acc: 0.9781\n",
            "Epoch 9/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0584 - acc: 0.9800\n",
            "Epoch 10/30\n",
            "151123/151123 [==============================] - 12s 81us/step - loss: 0.0549 - acc: 0.9811\n",
            "Epoch 11/30\n",
            "151123/151123 [==============================] - 12s 81us/step - loss: 0.0517 - acc: 0.9830\n",
            "Epoch 12/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0494 - acc: 0.9835\n",
            "Epoch 13/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0476 - acc: 0.9842\n",
            "Epoch 14/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0458 - acc: 0.9848\n",
            "Epoch 15/30\n",
            "151123/151123 [==============================] - 12s 81us/step - loss: 0.0444 - acc: 0.9852\n",
            "Epoch 16/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0432 - acc: 0.9859\n",
            "Epoch 17/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0419 - acc: 0.9862\n",
            "Epoch 18/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0409 - acc: 0.9866\n",
            "Epoch 19/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0402 - acc: 0.9870\n",
            "Epoch 20/30\n",
            "151123/151123 [==============================] - 12s 81us/step - loss: 0.0396 - acc: 0.9871\n",
            "Epoch 21/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0387 - acc: 0.9874\n",
            "Epoch 22/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0381 - acc: 0.9876\n",
            "Epoch 23/30\n",
            "151123/151123 [==============================] - 12s 81us/step - loss: 0.0374 - acc: 0.9879\n",
            "Epoch 24/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0369 - acc: 0.9882\n",
            "Epoch 25/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0363 - acc: 0.9885\n",
            "Epoch 26/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0353 - acc: 0.9888\n",
            "Epoch 27/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0349 - acc: 0.9888\n",
            "Epoch 28/30\n",
            "151123/151123 [==============================] - 12s 81us/step - loss: 0.0345 - acc: 0.9887\n",
            "Epoch 29/30\n",
            "151123/151123 [==============================] - 12s 81us/step - loss: 0.0341 - acc: 0.9891\n",
            "Epoch 30/30\n",
            "151123/151123 [==============================] - 12s 82us/step - loss: 0.0334 - acc: 0.9892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2200e7eba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "metadata": {
        "id": "LtY2ghu20oFu",
        "colab_type": "code",
        "outputId": "d7a12165-309f-4877-94df-463e300940b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = network.evaluate(X_test, y_test)\n",
        "print('test_acc:', test_acc, '             test_loss:', format(round(test_loss,4)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50375/50375 [==============================] - 2s 47us/step\n",
            "test_acc: 0.985727047146402              test_loss: 0.0444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WlGfx-Ix3rBv",
        "colab_type": "code",
        "outputId": "90d07d24-2a9f-45da-c467-77292190d215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred = network.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "#score = network.predict_proba(X_test)\n",
        "\n",
        "print(\"{:.3}\".format(accuracy_score(y_test, y_pred)))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.986\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99     47113\n",
            "           1       0.89      0.89      0.89      3262\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     50375\n",
            "   macro avg       0.94      0.94      0.94     50375\n",
            "weighted avg       0.99      0.99      0.99     50375\n",
            "\n",
            "[[46768   345]\n",
            " [  374  2888]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U9L1KN_p449v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename = 'glasses_keras_model.sav'\n",
        "pickle.dump(network, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9AW20I-l92HG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Glasses balanced\n"
      ]
    },
    {
      "metadata": {
        "id": "Fp6sr0EJBFDh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## undersample"
      ]
    },
    {
      "metadata": {
        "id": "bgxWly099z5r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "glas_under = pd.read_csv('/content/drive/My Drive/Colab/thesis/celeba/celeba_glasses_undersample.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zHfmWFLg-Ldu",
        "colab_type": "code",
        "outputId": "ca0de83d-837b-4f1e-dcb6-3add7982adaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "glas_under.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>encodings</th>\n",
              "      <th>file</th>\n",
              "      <th>Eyeglasses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-0.18005028  0.16697682  0.05575646 -0.046464...</td>\n",
              "      <td>009373.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-0.0319382  -0.01829863  0.04162911  0.043951...</td>\n",
              "      <td>072815.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-7.29213655e-02  1.29021764e-01  3.57191749e-...</td>\n",
              "      <td>156208.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-1.86423451e-01  2.16368176e-02  2.33115405e-...</td>\n",
              "      <td>087508.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-0.13597131  0.09287494  0.08348855 -0.114260...</td>\n",
              "      <td>129633.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           encodings        file  Eyeglasses\n",
              "0  [-0.18005028  0.16697682  0.05575646 -0.046464...  009373.jpg           0\n",
              "1  [-0.0319382  -0.01829863  0.04162911  0.043951...  072815.jpg           0\n",
              "2  [-7.29213655e-02  1.29021764e-01  3.57191749e-...  156208.jpg           0\n",
              "3  [-1.86423451e-01  2.16368176e-02  2.33115405e-...  087508.jpg           0\n",
              "4  [-0.13597131  0.09287494  0.08348855 -0.114260...  129633.jpg           0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "wqB5icoy_UaY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "glas = glas_under.Eyeglasses.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RV1DhPE_-YRv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "emb = glas_under.encodings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hLatzUG6-el5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "emb = (emb\n",
        " .str.replace('\\n','')\n",
        " .str.replace('\\r','')\n",
        " .str.replace('[','')\n",
        " .str.replace(']','')\n",
        " .str.split())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uGkYEviP-h7l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "emb_lists = emb.tolist()\n",
        "glas_under_emb_npy = np.asarray(emb_lists)\n",
        "glas_under_emb_npy = glas_under_emb_npy.astype(np.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C8v06lKN-yF5",
        "colab_type": "code",
        "outputId": "f9d7af81-a926-4aa8-d15d-65fc5dc5da13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "glas_under_emb_npy.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26098, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "metadata": {
        "id": "-pK94RzV_OQg",
        "colab_type": "code",
        "outputId": "f8727917-88a9-4682-e936-9af804701746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(glas_under_emb_npy, glas,test_size=0.25,random_state=91)\n",
        "\n",
        "print('train')\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print('test')\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "(19573, 128)\n",
            "(19573,)\n",
            "test\n",
            "(6525, 128)\n",
            "(6525,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jso1MA_a_zSN",
        "colab_type": "code",
        "outputId": "1d22f46c-5640-4498-df32-efc428287454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "Hnp59o0nAA8H",
        "colab_type": "code",
        "outputId": "6612ba2b-c752-45b6-998b-613f98948a4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0 9808]\n",
            " [   1 9765]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jvFLP9oNAUND",
        "colab_type": "code",
        "outputId": "cba0b949-8fbe-4480-e9a6-17a557aed8e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "model = SGDClassifier(loss='log', random_state=91, max_iter=30)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"{:.3}\".format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.822\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.84      0.83      3241\n",
            "           1       0.84      0.80      0.82      3284\n",
            "\n",
            "   micro avg       0.82      0.82      0.82      6525\n",
            "   macro avg       0.82      0.82      0.82      6525\n",
            "weighted avg       0.82      0.82      0.82      6525\n",
            "\n",
            "[[2734  507]\n",
            " [ 652 2632]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sq1dwoNwDfKc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename = 'glasses_undersample_model.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QUBU3uAjAf6d",
        "colab_type": "code",
        "outputId": "f51b06c8-1a68-465b-9fe0-f775a7bafdf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "model = SGDClassifier(loss='hinge', random_state=91, max_iter=40)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"{:.3}\".format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.826\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.87      0.83      3241\n",
            "           1       0.86      0.79      0.82      3284\n",
            "\n",
            "   micro avg       0.83      0.83      0.83      6525\n",
            "   macro avg       0.83      0.83      0.83      6525\n",
            "weighted avg       0.83      0.83      0.83      6525\n",
            "\n",
            "[[2805  436]\n",
            " [ 701 2583]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mRpZ_bvCc_2U",
        "colab_type": "code",
        "outputId": "2ba93c3b-6aad-4304-bfaf-f4a4b8572488",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1975
        }
      },
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(solver='adam', hidden_layer_sizes=(128, 128),max_iter = 100, verbose=True, tol=1e-4, activation='relu')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "score = clf.predict_proba(X_test)\n",
        "\n",
        "print(\"{:.3}\".format(accuracy_score(y_test, y_pred)))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53424794\n",
            "Iteration 2, loss = 0.39857400\n",
            "Iteration 3, loss = 0.35239553\n",
            "Iteration 4, loss = 0.31540660\n",
            "Iteration 5, loss = 0.27570451\n",
            "Iteration 6, loss = 0.23779965\n",
            "Iteration 7, loss = 0.21155538\n",
            "Iteration 8, loss = 0.18817204\n",
            "Iteration 9, loss = 0.16938368\n",
            "Iteration 10, loss = 0.15764286\n",
            "Iteration 11, loss = 0.14918152\n",
            "Iteration 12, loss = 0.13816624\n",
            "Iteration 13, loss = 0.12617975\n",
            "Iteration 14, loss = 0.12366871\n",
            "Iteration 15, loss = 0.11910825\n",
            "Iteration 16, loss = 0.11317809\n",
            "Iteration 17, loss = 0.10422210\n",
            "Iteration 18, loss = 0.10059747\n",
            "Iteration 19, loss = 0.10478558\n",
            "Iteration 20, loss = 0.09508409\n",
            "Iteration 21, loss = 0.09457967\n",
            "Iteration 22, loss = 0.09108568\n",
            "Iteration 23, loss = 0.09271219\n",
            "Iteration 24, loss = 0.08356225\n",
            "Iteration 25, loss = 0.08076858\n",
            "Iteration 26, loss = 0.07688617\n",
            "Iteration 27, loss = 0.08057987\n",
            "Iteration 28, loss = 0.07956205\n",
            "Iteration 29, loss = 0.07230805\n",
            "Iteration 30, loss = 0.07014070\n",
            "Iteration 31, loss = 0.06512222\n",
            "Iteration 32, loss = 0.06348723\n",
            "Iteration 33, loss = 0.06537249\n",
            "Iteration 34, loss = 0.06209059\n",
            "Iteration 35, loss = 0.06106733\n",
            "Iteration 36, loss = 0.05721175\n",
            "Iteration 37, loss = 0.06748279\n",
            "Iteration 38, loss = 0.05594858\n",
            "Iteration 39, loss = 0.05530405\n",
            "Iteration 40, loss = 0.05749610\n",
            "Iteration 41, loss = 0.05252474\n",
            "Iteration 42, loss = 0.04909422\n",
            "Iteration 43, loss = 0.04895366\n",
            "Iteration 44, loss = 0.04670889\n",
            "Iteration 45, loss = 0.04671197\n",
            "Iteration 46, loss = 0.04445980\n",
            "Iteration 47, loss = 0.04135514\n",
            "Iteration 48, loss = 0.04282925\n",
            "Iteration 49, loss = 0.03987708\n",
            "Iteration 50, loss = 0.03946287\n",
            "Iteration 51, loss = 0.03837326\n",
            "Iteration 52, loss = 0.03584555\n",
            "Iteration 53, loss = 0.04083450\n",
            "Iteration 54, loss = 0.03550572\n",
            "Iteration 55, loss = 0.03664523\n",
            "Iteration 56, loss = 0.03393650\n",
            "Iteration 57, loss = 0.03154342\n",
            "Iteration 58, loss = 0.03240295\n",
            "Iteration 59, loss = 0.03353301\n",
            "Iteration 60, loss = 0.02564581\n",
            "Iteration 61, loss = 0.03378059\n",
            "Iteration 62, loss = 0.02564757\n",
            "Iteration 63, loss = 0.02509895\n",
            "Iteration 64, loss = 0.03026140\n",
            "Iteration 65, loss = 0.03012798\n",
            "Iteration 66, loss = 0.02673533\n",
            "Iteration 67, loss = 0.02129895\n",
            "Iteration 68, loss = 0.02239919\n",
            "Iteration 69, loss = 0.03147457\n",
            "Iteration 70, loss = 0.02425660\n",
            "Iteration 71, loss = 0.01812654\n",
            "Iteration 72, loss = 0.01695220\n",
            "Iteration 73, loss = 0.01972351\n",
            "Iteration 74, loss = 0.02909422\n",
            "Iteration 75, loss = 0.01819914\n",
            "Iteration 76, loss = 0.01489867\n",
            "Iteration 77, loss = 0.01706765\n",
            "Iteration 78, loss = 0.02642615\n",
            "Iteration 79, loss = 0.01691703\n",
            "Iteration 80, loss = 0.03749849\n",
            "Iteration 81, loss = 0.01677238\n",
            "Iteration 82, loss = 0.01384352\n",
            "Iteration 83, loss = 0.01287582\n",
            "Iteration 84, loss = 0.01369760\n",
            "Iteration 85, loss = 0.02055204\n",
            "Iteration 86, loss = 0.01269603\n",
            "Iteration 87, loss = 0.01236786\n",
            "Iteration 88, loss = 0.00973854\n",
            "Iteration 89, loss = 0.01062424\n",
            "Iteration 90, loss = 0.01272132\n",
            "Iteration 91, loss = 0.01501186\n",
            "Iteration 92, loss = 0.01314065\n",
            "Iteration 93, loss = 0.01300195\n",
            "Iteration 94, loss = 0.04149702\n",
            "Iteration 95, loss = 0.01589582\n",
            "Iteration 96, loss = 0.01027457\n",
            "Iteration 97, loss = 0.00805444\n",
            "Iteration 98, loss = 0.00731517\n",
            "Iteration 99, loss = 0.00559195\n",
            "Iteration 100, loss = 0.00494989\n",
            "0.952\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95      3241\n",
            "           1       0.95      0.95      0.95      3284\n",
            "\n",
            "   micro avg       0.95      0.95      0.95      6525\n",
            "   macro avg       0.95      0.95      0.95      6525\n",
            "weighted avg       0.95      0.95      0.95      6525\n",
            "\n",
            "[[3091  150]\n",
            " [ 164 3120]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "KxDjWTQ-dpOK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename = 'glasses_mlp_undersample_model.sav'\n",
        "pickle.dump(clf, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VsSo2rSsA_A_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## oversample"
      ]
    },
    {
      "metadata": {
        "id": "pzrQfVP0AvwP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "glas_over = pd.read_csv('/content/drive/My Drive/Colab/thesis/celeba/celeba_glasses_oversample.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VrU4pb_0A6uC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "glas = glas_over.Eyeglasses.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hp1ersNsBPxh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "emb = glas_over.encodings\n",
        "\n",
        "emb = (emb\n",
        " .str.replace('\\n','')\n",
        " .str.replace('\\r','')\n",
        " .str.replace('[','')\n",
        " .str.replace(']','')\n",
        " .str.split())\n",
        "\n",
        "emb_lists = emb.tolist()\n",
        "glasover_emb_npy = np.asarray(emb_lists)\n",
        "glasover_emb_npy = glasover_emb_npy.astype(np.float)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3oIB2dAzBjo1",
        "colab_type": "code",
        "outputId": "beeb29da-b42d-4a13-f21c-fe7cbfae9099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(glasover_emb_npy, glas,test_size=0.25,random_state=91)\n",
        "\n",
        "print('train')\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print('test')\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "(282673, 128)\n",
            "(282673,)\n",
            "test\n",
            "(94225, 128)\n",
            "(94225,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lTAPdEoZCJKz",
        "colab_type": "code",
        "outputId": "09478535-37fc-4091-cbd6-af0d660cc9e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "model = SGDClassifier(loss='log', random_state=91, max_iter=30)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"{:.3}\".format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.832\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.87      0.84     47089\n",
            "           1       0.86      0.80      0.83     47136\n",
            "\n",
            "   micro avg       0.83      0.83      0.83     94225\n",
            "   macro avg       0.83      0.83      0.83     94225\n",
            "weighted avg       0.83      0.83      0.83     94225\n",
            "\n",
            "[[40847  6242]\n",
            " [ 9626 37510]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eMHxFN5eCAMx",
        "colab_type": "code",
        "outputId": "478972d6-9222-4a99-f74c-2f2986ec4e65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "model = SGDClassifier(loss='hinge', random_state=91, max_iter=40)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"{:.3}\".format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.836\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84     47089\n",
            "           1       0.86      0.81      0.83     47136\n",
            "\n",
            "   micro avg       0.84      0.84      0.84     94225\n",
            "   macro avg       0.84      0.84      0.84     94225\n",
            "weighted avg       0.84      0.84      0.84     94225\n",
            "\n",
            "[[40638  6451]\n",
            " [ 8995 38141]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kfKwWMxcCneb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename = 'glasses_oversample_model.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tTgqGjqNR8GA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# hair"
      ]
    },
    {
      "metadata": {
        "id": "ROXjcIiMR_uu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hairdf = pd.read_csv('/content/drive/My Drive/Colab/thesis/celeba/celeba_hair_dataset.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZJvCxmWISuB8",
        "colab_type": "code",
        "outputId": "5c48ce0c-968e-4af5-a552-f7cb35dd9e80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "hairdf.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>encodings</th>\n",
              "      <th>file</th>\n",
              "      <th>Black_Hair</th>\n",
              "      <th>Blond_Hair</th>\n",
              "      <th>Brown_Hair</th>\n",
              "      <th>Bald</th>\n",
              "      <th>score</th>\n",
              "      <th>color</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-0.10657232  0.12290111  0.06805265 -0.041072...</td>\n",
              "      <td>000001.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>brown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-0.11027038  0.02495586  0.05625371 -0.070694...</td>\n",
              "      <td>000002.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>brown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-0.01535916 -0.00451871  0.01638835  0.017832...</td>\n",
              "      <td>000006.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>brown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-1.45129263e-01  6.18378632e-02  6.61352053e-...</td>\n",
              "      <td>000007.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1000</td>\n",
              "      <td>black</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[ 0.02644151  0.15732542 -0.0238539   0.008128...</td>\n",
              "      <td>000008.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1000</td>\n",
              "      <td>black</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           encodings        file  Black_Hair  \\\n",
              "0  [-0.10657232  0.12290111  0.06805265 -0.041072...  000001.jpg           0   \n",
              "1  [-0.11027038  0.02495586  0.05625371 -0.070694...  000002.jpg           0   \n",
              "2  [-0.01535916 -0.00451871  0.01638835  0.017832...  000006.jpg           0   \n",
              "3  [-1.45129263e-01  6.18378632e-02  6.61352053e-...  000007.jpg           1   \n",
              "4  [ 0.02644151  0.15732542 -0.0238539   0.008128...  000008.jpg           1   \n",
              "\n",
              "   Blond_Hair  Brown_Hair  Bald  score  color  \n",
              "0           0           1     0     10  brown  \n",
              "1           0           1     0     10  brown  \n",
              "2           0           1     0     10  brown  \n",
              "3           0           0     0   1000  black  \n",
              "4           0           0     0   1000  black  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "metadata": {
        "id": "G6Jcgs2AS_Ue",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "color = hairdf.color.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e2pRHAraTJY4",
        "colab_type": "code",
        "outputId": "ae8f4756-525a-46df-aadd-25fd59d07ce9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "color.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119257,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "VKze5AOmSSGo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "emb = hairdf.encodings\n",
        "\n",
        "emb = (emb\n",
        " .str.replace('\\n','')\n",
        " .str.replace('\\r','')\n",
        " .str.replace('[','')\n",
        " .str.replace(']','')\n",
        " .str.split())\n",
        "\n",
        "emb_lists = emb.tolist()\n",
        "hair_emb_npy = np.asarray(emb_lists)\n",
        "hair_emb_npy = hair_emb_npy.astype(np.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sHpv7v4xSfEP",
        "colab_type": "code",
        "outputId": "8d71daa8-0c68-41f4-9bc8-31bed3c02cf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "hair_emb_npy.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119257, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "metadata": {
        "id": "QEMR2f92S2ys",
        "colab_type": "code",
        "outputId": "bfa9a84c-f7a1-4578-de38-0670acc88a1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "hair_emb_npy[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.10657232,  0.12290111,  0.06805265, -0.04107244, -0.09091284,\n",
              "        0.05011651, -0.07214841, -0.11483932,  0.21993797, -0.1022972 ,\n",
              "        0.27614293, -0.08339494, -0.3679857 ,  0.08410606, -0.08547532,\n",
              "        0.19960549, -0.26343495, -0.13145217, -0.12658648, -0.08161977,\n",
              "       -0.03662762, -0.0309852 ,  0.05915862,  0.11871034, -0.21404645,\n",
              "       -0.38162723, -0.01394539, -0.06993285, -0.03561937, -0.22256935,\n",
              "        0.02732605,  0.07517888, -0.15110423,  0.1061596 , -0.00903846,\n",
              "        0.1294672 , -0.01675487, -0.17476815,  0.20844407, -0.03255181,\n",
              "       -0.22278222, -0.10950559,  0.08133389,  0.29120237,  0.26651287,\n",
              "       -0.11200815,  0.01510113, -0.07966056,  0.15839767, -0.33412927,\n",
              "        0.01687353,  0.17194498,  0.05552776,  0.10473292,  0.15672114,\n",
              "       -0.1223305 , -0.00978362,  0.17710154, -0.09993096, -0.02218643,\n",
              "        0.10385877, -0.00371413,  0.05319744, -0.11833096,  0.27340212,\n",
              "        0.1250774 , -0.21254879, -0.11757348,  0.10648198, -0.15037501,\n",
              "       -0.06749468,  0.0942333 , -0.11888677, -0.23256616, -0.32712382,\n",
              "       -0.02681302,  0.34842646,  0.17459089, -0.18639067,  0.02628259,\n",
              "       -0.0664553 , -0.08417533, -0.01811093,  0.15788972, -0.04221157,\n",
              "        0.05381931, -0.13229328,  0.10894765,  0.25053343,  0.02139857,\n",
              "       -0.01804801,  0.26386768, -0.05085485, -0.08810563,  0.00697781,\n",
              "        0.11063426, -0.21190548, -0.03023176, -0.16656294, -0.04061881,\n",
              "       -0.00645296,  0.05621906, -0.02865896,  0.08631234, -0.14884366,\n",
              "        0.19000152, -0.02977185, -0.00845933, -0.01660807, -0.05313791,\n",
              "       -0.07988171,  0.02662071,  0.19494216, -0.3568058 ,  0.10998422,\n",
              "        0.07633387,  0.08209856,  0.09786627,  0.00550515,  0.03969587,\n",
              "       -0.01227501, -0.00342   , -0.10802871, -0.05281375, -0.0081524 ,\n",
              "       -0.08005548,  0.04871634, -0.00893142])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "KLdy21cvTUw_",
        "colab_type": "code",
        "outputId": "58267869-204c-436e-8a31-47bd5f068d15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(hair_emb_npy, color,test_size=0.25,random_state=91)\n",
        "\n",
        "print('train')\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print('test')\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "(89442, 128)\n",
            "(89442,)\n",
            "test\n",
            "(29815, 128)\n",
            "(29815,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EBOtK4m1Tgfp",
        "colab_type": "code",
        "outputId": "7ce2a80a-a430-45b9-c9c7-41855559a746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['bald' 3344]\n",
            " ['black' 35404]\n",
            " ['blond' 21475]\n",
            " ['brown' 29219]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fkJH62GDTxY0",
        "colab_type": "code",
        "outputId": "dc6380d4-253e-4c13-eb81-202b271e6109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(hair_emb_npy, color,test_size=0.25,random_state=91, stratify=color)\n",
        "\n",
        "print('train')\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print('test')\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "(89442, 128)\n",
            "(89442,)\n",
            "test\n",
            "(29815, 128)\n",
            "(29815,)\n",
            "[['bald' 3338]\n",
            " ['black' 35292]\n",
            " ['blond' 21498]\n",
            " ['brown' 29314]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-5fqZzKdUuN6",
        "colab_type": "code",
        "outputId": "ccf58648-806f-40bf-b1a9-c77d03914391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "cell_type": "code",
      "source": [
        "model = SGDClassifier(loss='log', random_state=91, max_iter=30)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"{:.3}\".format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.771\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        bald       0.80      0.51      0.62      1113\n",
            "       black       0.75      0.86      0.80     11764\n",
            "       blond       0.85      0.90      0.87      7166\n",
            "       brown       0.72      0.61      0.66      9772\n",
            "\n",
            "   micro avg       0.77      0.77      0.77     29815\n",
            "   macro avg       0.78      0.72      0.74     29815\n",
            "weighted avg       0.77      0.77      0.77     29815\n",
            "\n",
            "[[  568   426    32    87]\n",
            " [   46 10082    66  1570]\n",
            " [   32   104  6437   593]\n",
            " [   66  2751  1040  5915]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lnp_SzYZUBRN",
        "colab_type": "code",
        "outputId": "ba2a0b76-b2c0-48da-ea0a-f84f869b13fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "cell_type": "code",
      "source": [
        "model = SGDClassifier(loss='hinge', random_state=91, max_iter=100)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"{:.3}\".format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.773\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        bald       0.78      0.55      0.64      1113\n",
            "       black       0.76      0.85      0.80     11764\n",
            "       blond       0.85      0.90      0.87      7166\n",
            "       brown       0.72      0.62      0.67      9772\n",
            "\n",
            "   micro avg       0.77      0.77      0.77     29815\n",
            "   macro avg       0.78      0.73      0.75     29815\n",
            "weighted avg       0.77      0.77      0.77     29815\n",
            "\n",
            "[[ 609  399   19   86]\n",
            " [  52 9972   78 1662]\n",
            " [  37   96 6420  613]\n",
            " [  83 2571 1066 6052]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2zO1hcQgW0SM",
        "colab_type": "code",
        "outputId": "f2c06665-66d3-4a6b-ecee-4536d69947c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(solver='adam', hidden_layer_sizes=(128, 128),max_iter = 500, verbose=True, tol=1e-4, activation='relu')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "score = clf.predict_proba(X_test)\n",
        "\n",
        "print(\"{:.3}\".format(accuracy_score(y_test, y_pred)))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "\n",
        "#df_pred = pd.DataFrame(pred, columns=df_label.columns, index=Y_test.index)\n",
        "#df_score = pd.DataFrame(score, columns=df_label.columns, index=Y_test.index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.62456966\n",
            "Iteration 2, loss = 0.49296943\n",
            "Iteration 3, loss = 0.48427027\n",
            "Iteration 4, loss = 0.47597119\n",
            "Iteration 5, loss = 0.47031300\n",
            "Iteration 6, loss = 0.46588894\n",
            "Iteration 7, loss = 0.46297191\n",
            "Iteration 8, loss = 0.45766151\n",
            "Iteration 9, loss = 0.45545569\n",
            "Iteration 10, loss = 0.45194226\n",
            "Iteration 11, loss = 0.44928445\n",
            "Iteration 12, loss = 0.44400922\n",
            "Iteration 13, loss = 0.44201135\n",
            "Iteration 14, loss = 0.43864915\n",
            "Iteration 15, loss = 0.43615118\n",
            "Iteration 16, loss = 0.43207264\n",
            "Iteration 17, loss = 0.43020043\n",
            "Iteration 18, loss = 0.42831061\n",
            "Iteration 19, loss = 0.42501172\n",
            "Iteration 20, loss = 0.42261766\n",
            "Iteration 21, loss = 0.41887230\n",
            "Iteration 22, loss = 0.41739806\n",
            "Iteration 23, loss = 0.41473009\n",
            "Iteration 24, loss = 0.41294700\n",
            "Iteration 25, loss = 0.41033688\n",
            "Iteration 26, loss = 0.41024670\n",
            "Iteration 27, loss = 0.40632242\n",
            "Iteration 28, loss = 0.40333613\n",
            "Iteration 29, loss = 0.40226920\n",
            "Iteration 30, loss = 0.40055790\n",
            "Iteration 31, loss = 0.39766656\n",
            "Iteration 32, loss = 0.39586677\n",
            "Iteration 33, loss = 0.39313440\n",
            "Iteration 34, loss = 0.39257984\n",
            "Iteration 35, loss = 0.38975492\n",
            "Iteration 36, loss = 0.39029699\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.815\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        bald       0.81      0.80      0.80      1113\n",
            "       black       0.80      0.89      0.84     11764\n",
            "       blond       0.87      0.91      0.89      7166\n",
            "       brown       0.79      0.66      0.72      9772\n",
            "\n",
            "   micro avg       0.82      0.82      0.82     29815\n",
            "   macro avg       0.82      0.81      0.81     29815\n",
            "weighted avg       0.81      0.82      0.81     29815\n",
            "\n",
            "[[  889   165    18    41]\n",
            " [  104 10478    41  1141]\n",
            " [   32    53  6519   562]\n",
            " [   77  2355   921  6419]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MquQImu_BO7s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Fit LabelEncoder with our list of classes\n",
        "label_encoder = LabelEncoder()\n",
        "#label_encoder.fit(y_train)\n",
        "label_encoder.fit(color)\n",
        "\n",
        "# Encode class values as integers\n",
        "#y_train = label_encoder.transform(y_train)\n",
        "color = label_encoder.transform(color)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PNlBmEfEBm-a",
        "colab_type": "code",
        "outputId": "8430d08f-2666-49b2-d4ea-86c3b2729d37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(hair_emb_npy, color,test_size=0.25,random_state=91, stratify=color)\n",
        "\n",
        "print('train')\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print('test')\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "(89442, 128)\n",
            "(89442,)\n",
            "test\n",
            "(29815, 128)\n",
            "(29815,)\n",
            "[[    0  3338]\n",
            " [    1 35292]\n",
            " [    2 21498]\n",
            " [    3 29314]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A1iP2Ac7_lSc",
        "colab_type": "code",
        "outputId": "365bdcea-ca65-4235-ceab-1b9d67fcb735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        }
      },
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "#optimizers.RMSprop(lr=1e-4)\n",
        "\n",
        "hidden = 100\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(hidden, use_bias='true', activation='relu', input_shape=(128,)))\n",
        "network.add(layers.Dense(4, use_bias='true', activation='softmax'))\n",
        "\n",
        "keras.initializers.RandomNormal(mean=0.0, stddev=0.05)\n",
        "\n",
        "#keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
        "\n",
        "network.compile(optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "network.fit(X_train, y_train, epochs=30, batch_size=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "89442/89442 [==============================] - 8s 85us/step - loss: 0.5921 - acc: 0.7470\n",
            "Epoch 2/30\n",
            "89442/89442 [==============================] - 7s 82us/step - loss: 0.4941 - acc: 0.7874\n",
            "Epoch 3/30\n",
            "89442/89442 [==============================] - 7s 83us/step - loss: 0.4876 - acc: 0.7904\n",
            "Epoch 4/30\n",
            "89442/89442 [==============================] - 7s 83us/step - loss: 0.4827 - acc: 0.7936\n",
            "Epoch 5/30\n",
            "89442/89442 [==============================] - 7s 83us/step - loss: 0.4785 - acc: 0.7953\n",
            "Epoch 6/30\n",
            "89442/89442 [==============================] - 7s 83us/step - loss: 0.4739 - acc: 0.7972\n",
            "Epoch 7/30\n",
            "89442/89442 [==============================] - 7s 83us/step - loss: 0.4703 - acc: 0.7994\n",
            "Epoch 8/30\n",
            "89442/89442 [==============================] - 7s 83us/step - loss: 0.4664 - acc: 0.8010\n",
            "Epoch 9/30\n",
            "89442/89442 [==============================] - 7s 83us/step - loss: 0.4628 - acc: 0.8039\n",
            "Epoch 10/30\n",
            "89442/89442 [==============================] - 7s 82us/step - loss: 0.4587 - acc: 0.8049\n",
            "Epoch 11/30\n",
            "89442/89442 [==============================] - 7s 82us/step - loss: 0.4555 - acc: 0.8064\n",
            "Epoch 12/30\n",
            "89442/89442 [==============================] - 7s 83us/step - loss: 0.4525 - acc: 0.8076\n",
            "Epoch 13/30\n",
            "89442/89442 [==============================] - 7s 82us/step - loss: 0.4503 - acc: 0.8089\n",
            "Epoch 14/30\n",
            "89442/89442 [==============================] - 7s 82us/step - loss: 0.4475 - acc: 0.8102\n",
            "Epoch 15/30\n",
            "89442/89442 [==============================] - 7s 83us/step - loss: 0.4451 - acc: 0.8111\n",
            "Epoch 16/30\n",
            "89442/89442 [==============================] - 7s 82us/step - loss: 0.4427 - acc: 0.8120\n",
            "Epoch 17/30\n",
            "89442/89442 [==============================] - 7s 82us/step - loss: 0.4406 - acc: 0.8133\n",
            "Epoch 18/30\n",
            "89442/89442 [==============================] - 7s 82us/step - loss: 0.4391 - acc: 0.8138\n",
            "Epoch 19/30\n",
            "89442/89442 [==============================] - 7s 82us/step - loss: 0.4370 - acc: 0.8151\n",
            "Epoch 20/30\n",
            "89442/89442 [==============================] - 7s 82us/step - loss: 0.4343 - acc: 0.8168\n",
            "Epoch 21/30\n",
            "89442/89442 [==============================] - 7s 83us/step - loss: 0.4329 - acc: 0.8174\n",
            "Epoch 22/30\n",
            "89442/89442 [==============================] - 7s 83us/step - loss: 0.4318 - acc: 0.8179\n",
            "Epoch 23/30\n",
            "89442/89442 [==============================] - 7s 82us/step - loss: 0.4300 - acc: 0.8184\n",
            "Epoch 24/30\n",
            "89442/89442 [==============================] - 7s 83us/step - loss: 0.4278 - acc: 0.8204\n",
            "Epoch 25/30\n",
            "89442/89442 [==============================] - 7s 82us/step - loss: 0.4264 - acc: 0.8205\n",
            "Epoch 26/30\n",
            "89442/89442 [==============================] - 7s 82us/step - loss: 0.4244 - acc: 0.8216\n",
            "Epoch 27/30\n",
            "89442/89442 [==============================] - 7s 82us/step - loss: 0.4240 - acc: 0.8208\n",
            "Epoch 28/30\n",
            "89442/89442 [==============================] - 7s 82us/step - loss: 0.4214 - acc: 0.8232\n",
            "Epoch 29/30\n",
            "89442/89442 [==============================] - 7s 82us/step - loss: 0.4203 - acc: 0.8236\n",
            "Epoch 30/30\n",
            "89442/89442 [==============================] - 7s 83us/step - loss: 0.4192 - acc: 0.8238\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f22005e15f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "metadata": {
        "id": "GJuQIX_eBlTS",
        "colab_type": "code",
        "outputId": "4981c744-43ff-458b-af0a-57e82a8f4a01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred = network.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(\"{:.3}\".format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.804\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.77      0.79      1113\n",
            "           1       0.86      0.79      0.82     11764\n",
            "           2       0.89      0.89      0.89      7166\n",
            "           3       0.72      0.76      0.74      9772\n",
            "\n",
            "   micro avg       0.82      0.80      0.81     29815\n",
            "   macro avg       0.82      0.80      0.81     29815\n",
            "weighted avg       0.82      0.80      0.81     29815\n",
            " samples avg       0.80      0.80      0.80     29815\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-a5bf8cc2f553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: multilabel-indicator is not supported"
          ]
        }
      ]
    }
  ]
}